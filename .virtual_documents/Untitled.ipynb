import pandas as pd
from collections import defaultdict
from collections import Counter
import os
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.decomposition import PCA
import plotly.io as pio
pio.renderers.default = 'png'
import os
import numpy as np
import pandas as pd
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix







uci_test = pd.read_csv('./Data/UCI HAR Data Frame/uci_test.csv')
uci_train = pd.read_csv('./Data/UCI HAR Data Frame/uci_train.csv')
uci_df = pd.concat([uci_train,uci_test])
feature_cols = [c for c in uci_df.columns if c not in ('subject','activity')]

# Train-test split
X_train = uci_train[feature_cols]
y_train = uci_train['activity']
X_test = uci_test[feature_cols]
y_test = uci_test['activity']



uci_df





# Train SVM model
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)

#  Make predictions
y_pred = svm_model.predict(X_test)
svm_acc = accuracy_score(y_test,y_pred)

# Confusion Matrix
plt.figure(figsize=(6, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',
            xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)
plt.title("SVM Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()



# Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
rf_acc = accuracy_score(y_test, y_pred_rf)



## KNN
knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
knn_acc = accuracy_score(y_test, y_pred_knn)


#LOG-REG
logreg = LogisticRegression(multi_class='multinomial', max_iter=1000)
logreg.fit(X_train, y_train)
y_pred_log = logreg.predict(X_test)
logreg_acc = accuracy_score(y_test, y_pred_log)



# Train Decision Tree
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)
dt_acc = accuracy_score(y_test, y_pred_dt)

# Plot Decision Tree for max_depth = 3
dt_model3 = DecisionTreeClassifier(max_depth = 3)
dt_model3.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)
plt.figure(figsize=(20, 10))
plot_tree(dt_model3,
          filled=True,
          feature_names=X_train.columns,
          class_names=dt_model.classes_,
          rounded=True) 
plt.show()


# Print accuracy scores to compare different models

results = [{"Model": "SVM", "Accuracy": svm_acc},
           {"Model": "Logistic Regression", "Accuracy": logreg_acc},
           {"Model": "Random Forest", "Accuracy": rf_acc},
           {"Model": "KNN", "Accuracy": knn_acc},
           {"Model": "Decision Tree", "Accuracy": dt_acc}]

pd.DataFrame(results)






# Create correlation matrix
corr_matrix = uci_df[feature_cols].corr().abs()
fig, ax = plt.subplots(figsize = (10,8))
corr_heatmap = ax.matshow(corr_matrix, cmap = 'viridis', vmin = 0, vmax = 1)

fig.colorbar(corr_heatmap)
plt.title('Correlation HeatMap')
plt.tight_layout()
plt.show()



