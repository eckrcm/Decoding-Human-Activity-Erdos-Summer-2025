





import pandas as pd
from collections import defaultdict
from collections import Counter
import os
import numpy as np
import matplotlib.pyplot as plt














# ==== CONVERTING THE RAW UCI HAR DATASET INTO CLEAN PANDAS DATAFRAMES ====
# The original files are plain .txt files with duplicated feature names.
# This script loads, cleans, labels, and converts them into usable DataFrames.
base = "./Data/Human Activity Recognition using Smartphones/UCI HAR Dataset/"
X_train_path = base + "train/X_train.txt"
y_train_path = base + "train/y_train.txt"
subject_train_path = base + "train/subject_train.txt"
X_test_path = base + "test/X_test.txt"
y_test_path = base + "test/y_test.txt"
subject_test_path = base + "test/subject_test.txt"
features_path = base + "features.txt"
activity_labels_path = base + "activity_labels.txt"

# Load features with deduplication
features_path = "./Data/Human Activity Recognition using Smartphones/UCI HAR Dataset/features.txt"
features_df = pd.read_csv(features_path, sep=r"\s+", header=None)
raw_features = features_df[1].tolist()

# Deduplicate feature names
counts = defaultdict(int)
features = []
for name in raw_features:
    if counts[name]:
        new_name = f"{name}_{counts[name]}"
    else:
        new_name = name
    features.append(new_name)
    counts[name] += 1

# Load datasets
X_train = pd.read_csv(X_train_path, sep=r'\s+', header=None, names=features)
y_train = pd.read_csv(y_train_path, header=None, names=["activity"])
subject_train = pd.read_csv(subject_train_path, header=None, names=["subject"])
X_test = pd.read_csv(X_test_path, sep=r'\s+', header=None, names=features)
y_test = pd.read_csv(y_test_path, header=None, names=["activity"])
subject_test = pd.read_csv(subject_test_path, header=None, names=["subject"])

# Combine
train_df = pd.concat([subject_train, y_train, X_train], axis=1)
test_df = pd.concat([subject_test, y_test, X_test], axis=1)

# Activity label mapping
activity_labels = pd.read_csv(activity_labels_path, sep=r'\s+', header=None, names=["id", "label"])
activity_map = dict(zip(activity_labels.id, activity_labels.label))
train_df["activity"] = train_df["activity"].map(activity_map)
test_df["activity"] = test_df["activity"].map(activity_map)

# Save Dataframes
# cwd = os.getcwd()
# directory = os.path.join(cwd,"UCI HAR Data Frame")
# os.makedirs(directory,exist_ok = True)
# file_name_train = os.path.join(directory,"uci_train.csv")
# file_name_test  = os.path.join(directory,"uci_test.csv")

# train_df.to_csv(file_name_train,index = False)
# test_df.to_csv(file_name_test,index = False)

# == combine train and test ===
uci_df = pd.concat([train_df,test_df])














uci_df





uci_df.loc[uci_df["activity"] == "WALKING_DOWNSTAIRS"].iloc[:,:30]


uci_df.loc[uci_df["activity"] == 'WALKING_UPSTAIRS']








# compute some stat
number_of_subjects = len(uci_df["subject"].unique()) 
activities = uci_df["activity"].unique()
number_of_activities = len(activities) # different types of activities
number_of_sensor_features = 561

# == display ===
print("üìä Dataset Summary")
print("="*40)
print(f"üë§ Number of unique subjects        : {number_of_subjects}")
print(f"üèÉ Number of distinct activities    : {number_of_activities}")
print(f"üìà Number of sensor features        : {number_of_sensor_features}")
print()
print("üß≠ Activities:")
print(", ".join(activities))




fig, axes = plt.subplots(1, 2, figsize=(14, 5))  # 1 row, 2 columns

# Plot 1: Samples per Activity
uci_df["activity"].value_counts().plot(
    kind='bar',
    ax=axes[0],
    title="Samples per Activity",
    color="skyblue"
)
axes[0].set_ylabel("Count")
axes[0].tick_params(axis='x', rotation=45)

# Plot 2: Samples per Subject
uci_df["subject"].value_counts().sort_index().plot(
    kind='bar',
    ax=axes[1],
    title="Samples per Subject",
    color="salmon"
)
axes[1].set_ylabel("Count")
axes[1].tick_params(axis='x', rotation=90)

plt.tight_layout()
plt.show()

























































