import os
import numpy as np
import pandas as pd
from collections import defaultdict, Counter
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix



uci_test = pd.read_csv('./Data/UCI HAR Data Frame/uci_test.csv')
uci_train = pd.read_csv('./Data/UCI HAR Data Frame/uci_train.csv')
uci_df = pd.concat([uci_train,uci_test])
feature_cols = [c for c in uci_df.columns if c not in ('subject','activity')]


# Train-test split
X_train = uci_train[feature_cols]
y_train = uci_train['activity']
X_test = uci_test[feature_cols]
y_test = uci_test['activity']

# Train SVM model
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)

#  Make predictions
y_pred = svm_model.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(10, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',
            xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)
plt.title("SVM Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()



# Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

# Confusion Matrix
plt.figure(figsize=(10, 6))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens',
            xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)
plt.title("Random Forest Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()



## KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))



#LOG-REG
logreg = LogisticRegression(multi_class='multinomial', max_iter=1000)
logreg.fit(X_train, y_train)
y_pred_log = logreg.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))



# Train Decision Tree
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

y_pred_dt = dt_model.predict(X_test)

print("Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))



# Plot the tree
plt.figure(figsize=(20, 10))
plot_tree(dt_model_viz, 
          feature_names=feature_cols, 
          class_names=le.classes_, 
          filled=True, 
          rounded=True)
plt.show()



dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train_encoded)

importances = dt_model.feature_importances_
importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})

top_features = importance_df.sort_values(by='Importance', ascending=False).head(10)
print(top_features)



results = [
    {"Model": "SVM", "Accuracy": svm_acc, "Precision": svm_prec, "Recall": svm_rec, "F1-Score": svm_f1},
    {"Model": "KNN", "Accuracy": knn_acc, "Precision": knn_prec, "Recall": knn_rec, "F1-Score": knn_f1},
    {"Model": "Random Forest", "Accuracy": rf_acc, "Precision": rf_prec, "Recall": rf_rec, "F1-Score": rf_f1},
    {"Model": "Logistic Regression", "Accuracy": logreg_acc, "Precision": logreg_prec, "Recall": logreg_rec, "F1-Score": logreg_f1},
    {"Model": "Decision Tree", "Accuracy": dt_acc, "Precision": dt_prec, "Recall": dt_rec, "F1-Score": dt_f1},
]

comparison_df = pd.DataFrame(results)
display(comparison_df)
